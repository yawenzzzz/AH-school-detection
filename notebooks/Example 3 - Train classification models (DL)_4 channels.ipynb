{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbf457c",
   "metadata": {},
   "source": [
    "# Example 3 - Train classification models (DL)\n",
    "\n",
    "In this notebook, we'll train classification models (CNN, RF, PU-learning, Co-training), see how they performs? Also, saved those models for prediction on test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ad25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import random\n",
    "import shutil\n",
    "import copy\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31612be",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16533838",
   "metadata": {},
   "source": [
    "## Step 1. Transform train & test data\n",
    "\n",
    "In this step, we'll save npy file (0-255, 4 channels) into image, into train/class_x/ and test/class_x/ folders.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb82d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"npy/train\"\n",
    "train_dst = \"CNN_model/data/train\"\n",
    "test_dir = \"npy/test\"\n",
    "test_dst = \"CNN_model/data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2f8f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(train_dst + '/AH' + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "files = glob.glob(train_dst + '/NAH' + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "files = glob.glob(test_dst + '/AH' + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "files = glob.glob(test_dst + '/NAH' + '/*')\n",
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62785f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['AH', 'NAH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98b2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_k = 2087"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09117d5",
   "metadata": {},
   "source": [
    "First, get files for each class in Train folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b23390",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in class_names:\n",
    "    os.makedirs(os.path.join(train_dst, c), exist_ok=True)\n",
    "    if c == 'AH':\n",
    "        class_npy = [i for i in os.listdir(train_dir) if '4.npy' in i]\n",
    "    else:\n",
    "        neg_npy = [i for i in os.listdir(train_dir) if ('1.npy' in i) or ('2.npy' in i) or ('3.npy' in i)]\n",
    "        unlabeled_npy = [i for i in os.listdir(train_dir) if '0.npy' in i]\n",
    "        class_npy = neg_npy + random.sample(unlabeled_npy, 1 * max_k - len(neg_npy)) # keep 1:1 ratio\n",
    "    # begin copy\n",
    "    for item in class_npy:\n",
    "        item_src = os.path.join(train_dir, item)\n",
    "        npy = np.load(item_src)\n",
    "#         # save as img\n",
    "#         item_dst = os.path.join(train_dst, c, item.split('.')[0] + '.jpg') \n",
    "#         npy = npy[:, :, :3] # only first 3 channels\n",
    "#         img = Image.fromarray(npy, 'RGB')\n",
    "#         img.save(item_dst)\n",
    "        # save as npy\n",
    "        item_dst = os.path.join(train_dst, c, item)\n",
    "        npy = np.transpose(npy, (2, 0, 1))\n",
    "        np.save(item_dst, npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c06fed",
   "metadata": {},
   "source": [
    "Second, get files for each class in Test folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b7df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in class_names:\n",
    "    os.makedirs(os.path.join(test_dst, c), exist_ok=True)\n",
    "    if c == 'AH':\n",
    "        class_npy = [i for i in os.listdir(test_dir) if '4.npy' in i]\n",
    "    else:\n",
    "        class_npy = [i for i in os.listdir(test_dir) if ('1.npy' in i) or ('2.npy' in i) or ('3.npy' in i)]\n",
    "    # begin copy\n",
    "    for item in class_npy:\n",
    "        item_src = os.path.join(test_dir, item)\n",
    "        npy = np.load(item_src) # npy shape (100, 100, 4)\n",
    "#         item_dst = os.path.join(test_dst, c, item.split('.')[0] + '.jpg')\n",
    "#         npy = npy[:, :, :3] # only first 3 channels\n",
    "#         img = Image.fromarray(npy, 'RGB')\n",
    "#         img.save(item_dst)\n",
    "        # save as npy\n",
    "        item_dst = os.path.join(test_dst, c, item)\n",
    "        npy = np.transpose(npy, (2, 0, 1))\n",
    "        np.save(item_dst, npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a44bae",
   "metadata": {},
   "source": [
    "## Step 3. Prepare train & test data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a8989",
   "metadata": {},
   "source": [
    "Define data loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b04a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_size = 224 # 224 * 224\n",
    "# pretrained_means = [0.485, 0.456, 0.406] # for resnet\n",
    "# pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "# train_transforms = transforms.Compose([\n",
    "#                                        transforms.Resize(pretrained_size),\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        transforms.Normalize(mean=pretrained_means, \n",
    "#                                                             std=pretrained_stds)\n",
    "#                                       ])\n",
    "# test_transforms = transforms.Compose([\n",
    "#                                       transforms.Resize(pretrained_size),\n",
    "#                                       transforms.ToTensor(),\n",
    "#                                       transforms.Normalize(mean=pretrained_means, \n",
    "#                                                            std=pretrained_stds)\n",
    "#                                       ])\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ToPILImage(mode='RGBA'), transforms.ToTensor()])\n",
    "test_transforms = transforms.Compose([transforms.ToPILImage(mode='RGBA'), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1cd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load image\n",
    "# train_data = datasets.ImageFolder(root=train_dst, transform=train_transforms)\n",
    "# test_data = datasets.ImageFolder(root=test_dst, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72325d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load npy\n",
    "def npy_loader(path):\n",
    "    return torch.from_numpy(np.load(path))\n",
    "train_data = datasets.DatasetFolder(root=train_dst, loader=npy_loader, extensions=tuple(['.npy']), transform=train_transforms)\n",
    "test_data = datasets.DatasetFolder(root=test_dst, loader=npy_loader, extensions=tuple(['.npy']), transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1c85f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4174, 558)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc7426",
   "metadata": {},
   "source": [
    "Here, we create validation set from training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ea2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "train_data, valid_data = data.random_split(train_data, [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab0abe",
   "metadata": {},
   "source": [
    "Then overwrite the validation transforms, making sure to do a deepcopy to stop this also changing the training data transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca646e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4e68778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 3756\n",
      "Number of validation examples: 418\n",
      "Number of testing examples: 558\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1bb4e",
   "metadata": {},
   "source": [
    "Next, we create the iterators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94700a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # 32 or 64 got very similar results!\n",
    "train_iterator = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_iterator = data.DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "test_iterator = data.DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564fc8c",
   "metadata": {},
   "source": [
    "To ensure the images have been processed correctly we can plot a few of them - ensuring we re-normalize the images so their colors look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ff030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min=image_min, max=image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ca2773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels, classes, normalize=True):\n",
    "    n_images = len(images)\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))    \n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)        \n",
    "        image = images[i]\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        label = classes[labels[i]]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ce2fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_IMAGES = 25\n",
    "# images, labels = zip(*[(image, label) for image, label in [train_data[i] for i in range(N_IMAGES)]])\n",
    "# classes = test_data.classes\n",
    "# plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df27b16",
   "metadata": {},
   "source": [
    "## Step 3. Train classification models (CNN)\n",
    "\n",
    "In this step, we'll train classification models to differentiate AH and other categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bceb665",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_iterator, 'val': valid_iterator}\n",
    "dataset_sizes = {'train': n_train_examples, 'val': n_valid_examples}\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "516c4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92c8c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=False)\n",
    "# modify the first layer, see if it works!\n",
    "model_ft.conv1 = torch.nn.Conv2d(4, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False)\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb81c92",
   "metadata": {},
   "source": [
    "Note, here I met the issue: CUDA error: out of memory, Solution: use a smaller batch_size -> The error, which you has provided is shown, because you ran out of memory on your GPU. A way to solve it is to reduce the batch size until your code will run without this error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a44cb7",
   "metadata": {},
   "source": [
    "The training step would be 10x faster if using GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26cddf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yazh0781/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6121 Acc: 0.6337\n",
      "val Loss: 0.6449 Acc: 0.6842\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.5421 Acc: 0.7063\n",
      "val Loss: 0.5289 Acc: 0.7105\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.5092 Acc: 0.7370\n",
      "val Loss: 0.5432 Acc: 0.7153\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.4799 Acc: 0.7638\n",
      "val Loss: 0.5417 Acc: 0.7344\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.4359 Acc: 0.7931\n",
      "val Loss: 0.5430 Acc: 0.7273\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.4017 Acc: 0.8120\n",
      "val Loss: 0.5394 Acc: 0.7368\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.3725 Acc: 0.8291\n",
      "val Loss: 0.5827 Acc: 0.7201\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.2598 Acc: 0.9095\n",
      "val Loss: 0.4940 Acc: 0.7608\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.2370 Acc: 0.9167\n",
      "val Loss: 0.5025 Acc: 0.7512\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.2142 Acc: 0.9252\n",
      "val Loss: 0.4977 Acc: 0.7727\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.1964 Acc: 0.9337\n",
      "val Loss: 0.5152 Acc: 0.7727\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.1905 Acc: 0.9404\n",
      "val Loss: 0.5206 Acc: 0.7679\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.1668 Acc: 0.9481\n",
      "val Loss: 0.5233 Acc: 0.7536\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.1468 Acc: 0.9595\n",
      "val Loss: 0.5484 Acc: 0.7727\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.1391 Acc: 0.9675\n",
      "val Loss: 0.5475 Acc: 0.7632\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.1343 Acc: 0.9641\n",
      "val Loss: 0.5470 Acc: 0.7488\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.1411 Acc: 0.9609\n",
      "val Loss: 0.5529 Acc: 0.7632\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.1334 Acc: 0.9675\n",
      "val Loss: 0.5544 Acc: 0.7656\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.1297 Acc: 0.9704\n",
      "val Loss: 0.5512 Acc: 0.7656\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.1283 Acc: 0.9675\n",
      "val Loss: 0.5524 Acc: 0.7584\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.1417 Acc: 0.9579\n",
      "val Loss: 0.5622 Acc: 0.7560\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.1216 Acc: 0.9726\n",
      "val Loss: 0.5607 Acc: 0.7560\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.1260 Acc: 0.9720\n",
      "val Loss: 0.5579 Acc: 0.7679\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.1278 Acc: 0.9681\n",
      "val Loss: 0.5614 Acc: 0.7536\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.1291 Acc: 0.9678\n",
      "val Loss: 0.5555 Acc: 0.7632\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.1230 Acc: 0.9715\n",
      "val Loss: 0.5649 Acc: 0.7632\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.1273 Acc: 0.9702\n",
      "val Loss: 0.5592 Acc: 0.7727\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.1332 Acc: 0.9638\n",
      "val Loss: 0.5567 Acc: 0.7584\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.1257 Acc: 0.9707\n",
      "val Loss: 0.5539 Acc: 0.7679\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.1305 Acc: 0.9659\n",
      "val Loss: 0.5616 Acc: 0.7584\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.1272 Acc: 0.9712\n",
      "val Loss: 0.5519 Acc: 0.7656\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 0.9771\n",
      "val Loss: 0.5571 Acc: 0.7727\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.1230 Acc: 0.9707\n",
      "val Loss: 0.5524 Acc: 0.7679\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.1304 Acc: 0.9667\n",
      "val Loss: 0.5612 Acc: 0.7584\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.1256 Acc: 0.9688\n",
      "val Loss: 0.5591 Acc: 0.7632\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.1244 Acc: 0.9678\n",
      "val Loss: 0.5638 Acc: 0.7608\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.1237 Acc: 0.9686\n",
      "val Loss: 0.5697 Acc: 0.7536\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.1232 Acc: 0.9710\n",
      "val Loss: 0.5715 Acc: 0.7679\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.1296 Acc: 0.9678\n",
      "val Loss: 0.5507 Acc: 0.7632\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.1337 Acc: 0.9675\n",
      "val Loss: 0.5575 Acc: 0.7632\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.1250 Acc: 0.9704\n",
      "val Loss: 0.5642 Acc: 0.7727\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.1245 Acc: 0.9742\n",
      "val Loss: 0.5572 Acc: 0.7703\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.1268 Acc: 0.9688\n",
      "val Loss: 0.5565 Acc: 0.7656\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.1285 Acc: 0.9673\n",
      "val Loss: 0.5584 Acc: 0.7632\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.1276 Acc: 0.9707\n",
      "val Loss: 0.5594 Acc: 0.7632\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.1252 Acc: 0.9710\n",
      "val Loss: 0.5532 Acc: 0.7608\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.1287 Acc: 0.9681\n",
      "val Loss: 0.5632 Acc: 0.7679\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.1277 Acc: 0.9681\n",
      "val Loss: 0.5512 Acc: 0.7608\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.1330 Acc: 0.9643\n",
      "val Loss: 0.5588 Acc: 0.7656\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.1248 Acc: 0.9726\n",
      "val Loss: 0.5643 Acc: 0.7727\n",
      "\n",
      "Training complete in 5m 53s\n",
      "Best val Acc: 0.772727\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e35623",
   "metadata": {},
   "source": [
    "## Step 4. Test classification models\n",
    "\n",
    "In this step, we'll test classification to differentiate AH and other categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8709cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(iterator):\n",
    "    model_ft.eval()\n",
    "    pred_labels = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in iterator:\n",
    "            x = x.to(device)            \n",
    "            outputs = model_ft(x)\n",
    "            _, y_pred = torch.max(outputs, 1)\n",
    "            pred_labels.append(y_pred.cpu())\n",
    "            labels.append(y.cpu())\n",
    "    pred_labels = torch.cat(pred_labels, dim=0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    return labels, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7fe4c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(453.)\n"
     ]
    }
   ],
   "source": [
    "labels, pred_labels = get_predictions(test_iterator)\n",
    "print(torch.sum(labels == 0).float()) # 0: AH\n",
    "# print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29b7b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = torch.eq(labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a1443c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_true = torch.sum(labels == 0).float()\n",
    "predicted_true = torch.sum(pred_labels == 0).float()\n",
    "correct_true = torch.sum((pred_labels == labels) * (pred_labels == 0)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "030002a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7219) tensor(0.9478) tensor(0.8195)\n"
     ]
    }
   ],
   "source": [
    "recall = correct_true / target_true\n",
    "precision = correct_true / predicted_true\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "print(recall, precision, f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
