{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 10 - ROI pipeline (CNN features)\n",
    "\n",
    "In this notebook, we'll set up ROI pipeline:\n",
    "\n",
    "(1) Apply Sv threshold, given a range, use this threshold to detect ROIs\n",
    "(2) For each ROI, match with annotations, compute IoU, get labels for ROIs\n",
    "(3) For each ROI, save as numpy array, in filename, add contextual information (depth, relative altitude, lat/lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from src.read_echogram import EchogramReader\n",
    "from src.detect_ROI import ROIDetector\n",
    "from src.ROI_features_context import FeatureExtractor\n",
    "from src.transform_annotations import AnnotationTransformer\n",
    "from src.match_annotations import OverlapAnnotation\n",
    "from src.crop_ROI import ROICropper\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Basic setting\n",
    "\n",
    "In this step, we'll set up filenames (raw, bot) dir, threshold range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode: train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty npy\n",
    "npy_dir = \"npy/\" + mode + \"_new/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw + bot paths\n",
    "pkl_dir = \"pkl/\"\n",
    "with open(pkl_dir + f\"{mode}_li.pickle\", \"rb\") as handle:\n",
    "    data_li = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure dir\n",
    "fig_dir = \"figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold range\n",
    "threshold_li = [-54, -56, -58, -60, -62, -64, -66, -68, -70, -72, -74, -76, -78, -80] \n",
    "# freq selection\n",
    "freq_li = [18, 38, 120, 200]\n",
    "# kernel size\n",
    "kernel_size = 3\n",
    "# iou threshold\n",
    "iou_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in threshold_li:\n",
    "    new_npy_dir = npy_dir + \"threshold_\" + str(threshold)\n",
    "    if os.path.exists(new_npy_dir):\n",
    "        files = glob.glob(new_npy_dir + '/*')\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "    else:\n",
    "        os.mkdir(new_npy_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations\n",
    "with open(pkl_dir + 'annotations_dict_new_p4.pickle', 'rb') as handle:\n",
    "    annotations_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. ROI detection\n",
    "\n",
    "In this step, we'll detect ROIs with each Sv threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each Sv threshold\n",
    "    # for each filename\n",
    "        # detect ROI\n",
    "        # for each ROI, crop / save npy + get features\n",
    "        # for each ROI, overlap with annotations + get labels (change to IoU, 0.5 threshold)\n",
    "        # save in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_threshold(a):\n",
    "    i, j = a # [raw_path, bot_path]\n",
    "    # read echogram\n",
    "    echogram = EchogramReader(i, j, freq_li)\n",
    "    filename, Sv_npy, surface_idx, bottom_idx, time, depth, positions = echogram()\n",
    "    # select annotations\n",
    "    flag = False\n",
    "    if filename in annotations_dict:\n",
    "        annotations_idx, labels = annotations_dict[filename]\n",
    "        flag = True  \n",
    "    # Sv thresheld\n",
    "    for threshold in threshold_li:\n",
    "        # (1) detect ROIs\n",
    "        roi = ROIDetector(filename, Sv_npy, surface_idx, bottom_idx, fig_dir, threshold, kernel_size)\n",
    "        img_shape, contours = roi()\n",
    "        # (2) get contextual features\n",
    "        features = FeatureExtractor(filename, contours, Sv_npy, bottom_idx, time, depth, positions)\n",
    "        contours_sel, contours_features = features() \n",
    "        # (3) overlap with annotations, get labels\n",
    "        if flag == True:\n",
    "            overlap = OverlapAnnotation(filename, img_shape, annotations_idx, labels, contours_sel, fig_dir)\n",
    "            contours_labels = overlap.compute_iou(iou_threshold)\n",
    "        else:\n",
    "            contours_labels = [0] * len(contours_sel) # no annotations\n",
    "        # (4) save npy\n",
    "        new_npy_dir = npy_dir + \"threshold_\" + str(threshold) + '/'\n",
    "        crop = ROICropper(filename, contours_sel, contours_features, contours_labels, Sv_npy, new_npy_dir)\n",
    "        crop()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D20191113-T083150\n",
      "D20191014-T003421\n",
      "D20191109-T150801\n",
      "D20191021-T204829\n",
      "D20191109-T154858\n",
      "D20191031-T045858\n",
      "D20190930-T235233\n",
      "D20191001-T204744\n",
      "D20191003-T044219\n",
      "D20190926-T091313\n",
      "D20191111-T165715\n",
      "D20191001-T233426\n",
      "D20191003-T021135\n",
      "D20191110-T190705\n",
      "D20191017-T145540\n",
      "D20191109-T134607\n",
      "D20191104-T124305\n",
      "D20191104-T193349\n",
      "D20191022-T083746\n",
      "D20191103-T230131\n",
      "D20191021-T192503\n",
      "D20191107-T192619\n",
      "D20191101-T135856\n",
      "D20190927-T010917\n",
      "D20190926-T160853\n",
      "D20190928-T164457\n",
      "D20191024-T213721\n",
      "D20191019-T200745\n",
      "D20191104-T010446\n",
      "D20191023-T212900\n",
      "D20190928-T232513\n",
      "D20191023-T122637\n",
      "D20191104-T221808\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(10)\n",
    "res_li = pool.map(roi_threshold, data_li) # list of [raw_path, bot_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Unclassified regions': 1, 'krill_schools': 2, 'fish_school': 3, 'AH_School': 4\n",
    "# 50 echograms - 1 day\n",
    "# add break, early stopping! -> start: 9:15 pm\n",
    "# annotations to cv2, fail, Umat for array, Use, try except instead!\n",
    "# est. 6 hours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
