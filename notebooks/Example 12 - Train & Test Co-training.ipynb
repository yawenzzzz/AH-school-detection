{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 12 - Train Co-training\n",
    "\n",
    "In this notebook, we'll set up the co-training process: (1) read cropped samples, get (npy, contextual features, label), (2) for each threshold: use train, conduct co-training, what is loss function? classify AH or not, use val to perform early stopping, select parameters, (3) each threshold has a co-training model, apply to test data, classifiation results, TP = classify (detect as P) as P, FP = classify (detect not P) as P, total P = number of P in annotations, recall = TP/#P, precision = TP/(TP + FP). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from skorch import NeuralNetClassifier, NeuralNetBinaryClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from src.classifiers import CoTrainingClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load train and val dataset\n",
    "\n",
    "In this step, we'll load train and val dataset. Besides npy data, also need to extract contextual features, and labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotations\n",
    "pkl_dir = \"pkl/\"\n",
    "with open(pkl_dir + 'annotations_dict_new_p4.pickle', 'rb') as handle:\n",
    "    annotations_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"npy/train/\"\n",
    "val_dir = \"npy/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold range\n",
    "threshold_li = [-54, -56, -58, -60, -62, -64, -66, -68, -70, -72, -74, -76, -78, -80] \n",
    "threshold = -66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for a certain threshold\n",
    "# Note: X, y, all numpy arrays, in shape (n_samples, n_channels, width, height), (n_samples, )\n",
    "def get_train_data(threshold):\n",
    "    new_train_dir = train_dir + \"threshold_\" + str(threshold)\n",
    "    new_val_dir = val_dir + \"threshold_\" + str(threshold)\n",
    "    # merge\n",
    "    # all_files = glob.glob(new_train_dir + '/*') + glob.glob(new_val_dir + '/*')\n",
    "    all_files = glob.glob(new_train_dir + '/*')\n",
    "    # export\n",
    "    all_npy = []\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    print(len(all_files))\n",
    "    pos_num = 0\n",
    "    neg_num = 0\n",
    "    unlabeled_num = 0\n",
    "    for idx, file in enumerate(all_files):\n",
    "        if idx % 10000 == 0:\n",
    "            print(idx)\n",
    "        # get contextual features\n",
    "        features = (file.split('/')[3]).split('_')\n",
    "        filename = features[0]\n",
    "        features_dict = {'total_water_column': float(features[2]), 'depth': float(features[3]), 'relative_altitude': float(features[4]), 'latitude': float(features[5]), 'longitude': float(features[6]), 'time': features[7]}               \n",
    "        # get label: 0 - neg, 1 - pos, -1 - unlabeled\n",
    "        label = int(features[8].split('.')[0])\n",
    "        if label == 4:\n",
    "            label = 1\n",
    "            pos_num += 1\n",
    "        elif label == 0:\n",
    "            # check, if no annotations on that file\n",
    "            if filename in annotations_dict:\n",
    "                label = -1\n",
    "            else:\n",
    "                label = 0 # get negative                \n",
    "        else:\n",
    "            label = -2\n",
    "        # select, pos_num keeps increasing! how about small objects?\n",
    "        if (label == 1) or (label == -2) or ((label == 0) and (neg_num <= pos_num * 5)) or ((label == -1) and (unlabeled_num <= (pos_num + neg_num) * 1)): \n",
    "            # get npy (time consuming)\n",
    "            npy = np.load(file)\n",
    "            npy = np.transpose(npy, (2, 0, 1))\n",
    "            # add\n",
    "            all_npy.append(npy)\n",
    "            all_features.append(features_dict)   \n",
    "            if label == -2:\n",
    "                label = 0 # reassign\n",
    "            all_labels.append(label)\n",
    "            if label == 0:\n",
    "                neg_num += 1\n",
    "            if label == -1:\n",
    "                unlabeled_num += 1\n",
    "    return np.array(all_npy), all_features, np.array(all_labels)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256216\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n"
     ]
    }
   ],
   "source": [
    "X1, X_feats_train, y = get_train_data(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert to X2, (n_samples, n_features)\n",
    "feats_df = pd.DataFrame(X_feats_train)\n",
    "sel_feats = ['depth', 'total_water_column', 'latitude', 'longitude']\n",
    "feats_df_sel = feats_df[sel_feats] # select features\n",
    "X2 = feats_df_sel.values\n",
    "# impute nan\n",
    "X2 = np.nan_to_num(X2) # some NaN in X2, impute use 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X1 to float\n",
    "X1 = X1.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8601, 4, 100, 100)\n",
      "(8601, 4)\n",
      "(array([-1,  0,  1]), array([4301, 3581,  719]))\n",
      "(8601,)\n"
     ]
    }
   ],
   "source": [
    "# check shape, train: 256216, val: 90844\n",
    "# labeled: 1240\n",
    "# select process, keep labeled & unlabeled in 1:2\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "print(np.unique(y, return_counts=True))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Define CNN model\n",
    "\n",
    "In this step, we'll use skorch library to define CNN model, in particular, use ResNet18 model with 4 channels as input. The purpose is to wrap CNN model with different methods, fit, predict, predict_proba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NVIDIA GeForce GTX 1080 Ti', 'NVIDIA GeForce GTX 1080 Ti')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0), torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_ft = models.resnet18(pretrained=False)\n",
    "# change input to 4 channels\n",
    "model_ft.conv1 = torch.nn.Conv2d(4, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False) # 4 channels\n",
    "# define device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "cnn_1 = NeuralNetClassifier(model_ft, criterion=nn.CrossEntropyLoss(), max_epochs=20, lr=0.001, optimizer=optim.Adam, device=device)\n",
    "# by default, 80/20 - train/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Train & Test Co-training\n",
    "\n",
    "In this step, we'll set up co-training using CNN and RF model. Each model uses different features, i.e., npy, and contextual features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.1321\u001b[0m       \u001b[32m0.8012\u001b[0m        \u001b[35m0.6857\u001b[0m  2.7065\n",
      "      2        \u001b[36m0.2339\u001b[0m       \u001b[32m0.8233\u001b[0m        \u001b[35m0.3427\u001b[0m  2.1400\n",
      "      3        \u001b[36m0.1895\u001b[0m       \u001b[32m0.8337\u001b[0m        \u001b[35m0.2752\u001b[0m  2.1144\n",
      "      4        \u001b[36m0.1642\u001b[0m       \u001b[32m0.8477\u001b[0m        \u001b[35m0.2596\u001b[0m  2.1166\n",
      "      5        \u001b[36m0.1475\u001b[0m       0.8442        0.3029  2.0980\n",
      "      6        \u001b[36m0.1412\u001b[0m       0.8326        0.3850  2.0969\n",
      "      7        \u001b[36m0.1284\u001b[0m       \u001b[32m0.8744\u001b[0m        0.2657  2.1100\n",
      "      8        0.1334       0.8663        0.3309  2.1038\n",
      "      9        0.1339       0.8651        0.3460  2.0963\n",
      "     10        \u001b[36m0.1225\u001b[0m       0.8640        0.2719  2.0954\n",
      "     11        \u001b[36m0.1028\u001b[0m       0.8512        0.4703  2.1079\n",
      "     12        0.1292       0.8570        0.3463  2.1050\n",
      "     13        \u001b[36m0.0993\u001b[0m       0.8674        0.3316  2.1287\n",
      "     14        0.1127       0.8500        0.4278  2.1800\n",
      "     15        0.1096       0.8744        0.3712  2.0988\n",
      "     16        \u001b[36m0.0940\u001b[0m       0.8721        0.3082  2.1128\n",
      "     17        \u001b[36m0.0914\u001b[0m       0.8581        0.4240  2.1145\n",
      "     18        \u001b[36m0.0912\u001b[0m       0.8663        0.3852  2.1135\n",
      "     19        \u001b[36m0.0700\u001b[0m       \u001b[32m0.8837\u001b[0m        0.3110  2.1236\n",
      "     20        \u001b[36m0.0534\u001b[0m       0.8698        0.2785  2.1185\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.1103\u001b[0m       \u001b[32m0.8980\u001b[0m        \u001b[35m0.2301\u001b[0m  2.1282\n",
      "      2        \u001b[36m0.0649\u001b[0m       0.8888        0.3049  2.1765\n",
      "      3        \u001b[36m0.0614\u001b[0m       0.8830        0.3394  2.1592\n",
      "      4        \u001b[36m0.0517\u001b[0m       0.8644        0.3902  2.1221\n",
      "      5        0.0593       0.8679        0.3786  2.1258\n",
      "      6        \u001b[36m0.0416\u001b[0m       0.8667        0.4725  2.1325\n",
      "      7        \u001b[36m0.0316\u001b[0m       \u001b[32m0.9143\u001b[0m        0.3248  2.1401\n",
      "      8        0.0468       0.8760        0.4841  2.1654\n",
      "      9        \u001b[36m0.0277\u001b[0m       0.8667        0.5782  2.1077\n",
      "     10        0.0349       0.8598        0.7500  2.1094\n",
      "     11        0.0281       0.8505        0.7924  2.1107\n",
      "     12        0.0374       0.6350        1.8341  2.1265\n",
      "     13        \u001b[36m0.0254\u001b[0m       0.8598        0.6592  2.1128\n",
      "     14        0.0343       0.8575        0.8067  2.1192\n",
      "     15        0.0308       0.8540        0.8608  2.1231\n",
      "     16        0.0344       0.8760        0.5656  2.1088\n",
      "     17        \u001b[36m0.0199\u001b[0m       0.8806        0.4667  2.1127\n",
      "     18        \u001b[36m0.0077\u001b[0m       0.8725        0.6407  2.1145\n",
      "     19        \u001b[36m0.0012\u001b[0m       0.8725        0.7372  2.1309\n",
      "     20        \u001b[36m0.0004\u001b[0m       0.8691        0.7857  2.1219\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0117\u001b[0m       \u001b[32m0.8624\u001b[0m        \u001b[35m0.7974\u001b[0m  2.2324\n",
      "      2        0.0428       \u001b[32m0.8798\u001b[0m        \u001b[35m0.5946\u001b[0m  2.1796\n",
      "      3        0.0252       0.8590        0.7445  2.1704\n",
      "      4        \u001b[36m0.0105\u001b[0m       0.8555        0.8806  2.1320\n",
      "      5        \u001b[36m0.0057\u001b[0m       \u001b[32m0.8902\u001b[0m        0.6133  2.1364\n",
      "      6        \u001b[36m0.0034\u001b[0m       0.8682        0.8515  2.1375\n",
      "      7        \u001b[36m0.0006\u001b[0m       0.8763        0.7724  2.1300\n",
      "      8        \u001b[36m0.0003\u001b[0m       0.8763        0.8073  2.1347\n",
      "      9        \u001b[36m0.0001\u001b[0m       0.8740        0.8550  2.1436\n",
      "     10        \u001b[36m0.0001\u001b[0m       0.8751        0.8632  2.1442\n",
      "     11        \u001b[36m0.0001\u001b[0m       0.8751        0.8813  2.1359\n",
      "     12        \u001b[36m0.0000\u001b[0m       0.8751        0.8978  2.1327\n",
      "     13        \u001b[36m0.0000\u001b[0m       0.8751        0.9122  2.1429\n",
      "     14        \u001b[36m0.0000\u001b[0m       0.8751        0.9252  2.1660\n",
      "     15        \u001b[36m0.0000\u001b[0m       0.8751        0.9371  2.1698\n",
      "     16        \u001b[36m0.0000\u001b[0m       0.8751        0.9482  2.1780\n",
      "     17        \u001b[36m0.0000\u001b[0m       0.8751        0.9587  2.1528\n",
      "     18        \u001b[36m0.0000\u001b[0m       0.8751        0.9686  2.1694\n",
      "     19        \u001b[36m0.0000\u001b[0m       0.8751        0.9780  2.1848\n",
      "     20        \u001b[36m0.0000\u001b[0m       0.8751        0.9871  2.1506\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0232\u001b[0m       \u001b[32m0.8756\u001b[0m        \u001b[35m0.7277\u001b[0m  2.1680\n",
      "      2        \u001b[36m0.0199\u001b[0m       \u001b[32m0.8859\u001b[0m        \u001b[35m0.4803\u001b[0m  2.1555\n",
      "      3        \u001b[36m0.0068\u001b[0m       0.8721        0.8439  2.1763\n",
      "      4        0.0085       0.8664        1.0360  2.1546\n",
      "      5        0.0095       0.8836        0.6095  2.1516\n",
      "      6        \u001b[36m0.0054\u001b[0m       0.8802        0.7364  2.1702\n",
      "      7        \u001b[36m0.0016\u001b[0m       0.8848        0.7884  2.2415\n",
      "      8        \u001b[36m0.0003\u001b[0m       0.8802        0.8185  2.1333\n",
      "      9        \u001b[36m0.0001\u001b[0m       0.8825        0.8611  2.1514\n",
      "     10        \u001b[36m0.0000\u001b[0m       0.8825        0.8771  2.1244\n",
      "     11        \u001b[36m0.0000\u001b[0m       0.8813        0.8899  2.1202\n",
      "     12        \u001b[36m0.0000\u001b[0m       0.8813        0.9018  2.1360\n",
      "     13        \u001b[36m0.0000\u001b[0m       0.8813        0.9130  2.1364\n",
      "     14        \u001b[36m0.0000\u001b[0m       0.8813        0.9237  2.1584\n",
      "     15        \u001b[36m0.0000\u001b[0m       0.8813        0.9337  2.1314\n",
      "     16        \u001b[36m0.0000\u001b[0m       0.8813        0.9433  2.1279\n",
      "     17        \u001b[36m0.0000\u001b[0m       0.8813        0.9523  2.1651\n",
      "     18        \u001b[36m0.0000\u001b[0m       0.8813        0.9610  2.1386\n",
      "     19        \u001b[36m0.0000\u001b[0m       0.8813        0.9693  2.1352\n",
      "     20        \u001b[36m0.0000\u001b[0m       0.8813        0.9773  2.1333\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0137\u001b[0m       \u001b[32m0.8816\u001b[0m        \u001b[35m0.6385\u001b[0m  2.1404\n",
      "      2        0.0368       \u001b[32m0.8897\u001b[0m        \u001b[35m0.4654\u001b[0m  2.1486\n",
      "      3        0.0199       0.8632        0.7378  2.1469\n",
      "      4        \u001b[36m0.0070\u001b[0m       0.8736        0.8466  2.1304\n",
      "      5        \u001b[36m0.0019\u001b[0m       0.8759        0.7752  2.1517\n",
      "      6        \u001b[36m0.0003\u001b[0m       0.8782        0.8365  2.1401\n",
      "      7        \u001b[36m0.0001\u001b[0m       0.8770        0.8782  2.1652\n",
      "      8        \u001b[36m0.0001\u001b[0m       0.8770        0.9058  2.1463\n",
      "      9        \u001b[36m0.0001\u001b[0m       0.8770        0.9275  2.2006\n",
      "     10        \u001b[36m0.0000\u001b[0m       0.8770        0.9461  2.1520\n",
      "     11        \u001b[36m0.0000\u001b[0m       0.8759        0.9626  2.1825\n",
      "     12        \u001b[36m0.0000\u001b[0m       0.8759        0.9776  2.1676\n",
      "     13        \u001b[36m0.0000\u001b[0m       0.8770        0.9914  2.1676\n",
      "     14        \u001b[36m0.0000\u001b[0m       0.8747        1.0042  2.1616\n",
      "     15        \u001b[36m0.0000\u001b[0m       0.8747        1.0162  2.1345\n",
      "     16        \u001b[36m0.0000\u001b[0m       0.8736        1.0275  2.1693\n",
      "     17        \u001b[36m0.0000\u001b[0m       0.8736        1.0381  2.1827\n",
      "     18        \u001b[36m0.0000\u001b[0m       0.8736        1.0482  2.1733\n",
      "     19        \u001b[36m0.0000\u001b[0m       0.8747        1.0578  2.1723\n",
      "     20        \u001b[36m0.0000\u001b[0m       0.8747        1.0670  2.1743\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0138\u001b[0m       \u001b[32m0.8830\u001b[0m        \u001b[35m1.1997\u001b[0m  2.1727\n",
      "      2        0.0553       0.8612        \u001b[35m0.7968\u001b[0m  2.2135\n",
      "      3        \u001b[36m0.0101\u001b[0m       0.8716        0.8128  2.1552\n",
      "      4        \u001b[36m0.0023\u001b[0m       0.8750        0.8011  2.1585\n",
      "      5        \u001b[36m0.0005\u001b[0m       0.8716        0.8910  2.1604\n",
      "      6        \u001b[36m0.0002\u001b[0m       0.8704        0.9297  2.1665\n",
      "      7        \u001b[36m0.0002\u001b[0m       0.8704        0.9520  2.1588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        \u001b[36m0.0001\u001b[0m       0.8704        0.9711  2.1825\n",
      "      9        \u001b[36m0.0001\u001b[0m       0.8704        0.9879  2.1844\n",
      "     10        \u001b[36m0.0001\u001b[0m       0.8704        1.0027  2.1711\n",
      "     11        \u001b[36m0.0001\u001b[0m       0.8704        1.0160  2.1792\n",
      "     12        \u001b[36m0.0001\u001b[0m       0.8704        1.0283  2.1532\n",
      "     13        \u001b[36m0.0001\u001b[0m       0.8704        1.0397  2.1503\n",
      "     14        \u001b[36m0.0000\u001b[0m       0.8704        1.0503  2.1550\n",
      "     15        \u001b[36m0.0000\u001b[0m       0.8704        1.0603  2.1496\n",
      "     16        \u001b[36m0.0000\u001b[0m       0.8704        1.0697  2.1481\n",
      "     17        \u001b[36m0.0000\u001b[0m       0.8716        1.0787  2.1635\n",
      "     18        \u001b[36m0.0000\u001b[0m       0.8716        1.0872  2.1656\n",
      "     19        \u001b[36m0.0000\u001b[0m       0.8716        1.0954  2.1603\n",
      "     20        \u001b[36m0.0000\u001b[0m       0.8716        1.1032  2.1555\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0100\u001b[0m       \u001b[32m0.8526\u001b[0m        \u001b[35m1.2223\u001b[0m  2.1695\n",
      "      2        0.0234       \u001b[32m0.8834\u001b[0m        \u001b[35m0.5983\u001b[0m  2.1621\n",
      "      3        0.0132       0.8789        0.6395  2.1614\n",
      "      4        \u001b[36m0.0031\u001b[0m       0.8789        0.7992  2.2039\n",
      "      5        \u001b[36m0.0002\u001b[0m       0.8800        0.8903  2.1810\n",
      "      6        \u001b[36m0.0001\u001b[0m       0.8789        0.9035  2.1640\n",
      "      7        \u001b[36m0.0001\u001b[0m       0.8777        0.9176  2.1638\n",
      "      8        \u001b[36m0.0000\u001b[0m       0.8777        0.9321  2.1548\n",
      "      9        \u001b[36m0.0000\u001b[0m       0.8777        0.9457  2.1589\n",
      "     10        \u001b[36m0.0000\u001b[0m       0.8777        0.9582  2.1621\n",
      "     11        \u001b[36m0.0000\u001b[0m       0.8777        0.9701  2.1581\n",
      "     12        \u001b[36m0.0000\u001b[0m       0.8777        0.9809  2.1895\n",
      "     13        \u001b[36m0.0000\u001b[0m       0.8777        0.9922  2.2015\n",
      "     14        \u001b[36m0.0000\u001b[0m       0.8777        1.0011  2.1661\n",
      "     15        \u001b[36m0.0000\u001b[0m       0.8777        1.0123  2.1972\n",
      "     16        \u001b[36m0.0000\u001b[0m       0.8777        1.0198  2.2453\n",
      "     17        \u001b[36m0.0000\u001b[0m       0.8777        1.0302  2.1918\n",
      "     18        \u001b[36m0.0000\u001b[0m       0.8777        1.0367  2.1804\n",
      "     19        \u001b[36m0.0000\u001b[0m       0.8777        1.0470  2.2239\n",
      "     20        \u001b[36m0.0000\u001b[0m       0.8777        1.0530  2.1693\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0122\u001b[0m       \u001b[32m0.8894\u001b[0m        \u001b[35m0.9017\u001b[0m  2.2165\n",
      "      2        0.0186       0.8814        \u001b[35m0.8256\u001b[0m  2.2025\n",
      "      3        \u001b[36m0.0111\u001b[0m       0.8780        \u001b[35m0.5926\u001b[0m  2.2008\n",
      "      4        \u001b[36m0.0046\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m0.5651\u001b[0m  2.1774\n",
      "      5        \u001b[36m0.0016\u001b[0m       0.8757        0.7874  2.2064\n",
      "      6        \u001b[36m0.0002\u001b[0m       0.8826        0.7566  2.1914\n",
      "      7        \u001b[36m0.0001\u001b[0m       0.8780        0.7957  2.1706\n",
      "      8        \u001b[36m0.0001\u001b[0m       0.8791        0.8162  2.1665\n",
      "      9        \u001b[36m0.0000\u001b[0m       0.8803        0.8291  2.2215\n",
      "     10        \u001b[36m0.0000\u001b[0m       0.8803        0.8406  2.2242\n",
      "     11        \u001b[36m0.0000\u001b[0m       0.8803        0.8512  2.1884\n",
      "     12        \u001b[36m0.0000\u001b[0m       0.8803        0.8611  2.2433\n",
      "     13        \u001b[36m0.0000\u001b[0m       0.8803        0.8704  2.1910\n",
      "     14        \u001b[36m0.0000\u001b[0m       0.8803        0.8792  2.1866\n",
      "     15        \u001b[36m0.0000\u001b[0m       0.8803        0.8875  2.2096\n",
      "     16        \u001b[36m0.0000\u001b[0m       0.8803        0.8953  2.1544\n",
      "     17        \u001b[36m0.0000\u001b[0m       0.8791        0.9028  2.1687\n",
      "     18        \u001b[36m0.0000\u001b[0m       0.8803        0.9100  2.1676\n",
      "     19        \u001b[36m0.0000\u001b[0m       0.8803        0.9168  2.1582\n",
      "     20        \u001b[36m0.0000\u001b[0m       0.8803        0.9233  2.1632\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0066\u001b[0m       \u001b[32m0.8750\u001b[0m        \u001b[35m0.8967\u001b[0m  2.1779\n",
      "      2        0.0088       0.8648        1.0569  2.1677\n",
      "      3        \u001b[36m0.0046\u001b[0m       0.8682        1.3885  2.1818\n",
      "      4        0.0068       0.8727        0.9019  2.1941\n",
      "      5        0.0140       0.8727        \u001b[35m0.6960\u001b[0m  2.1974\n",
      "      6        0.0057       \u001b[32m0.8761\u001b[0m        \u001b[35m0.6754\u001b[0m  2.1812\n",
      "      7        \u001b[36m0.0033\u001b[0m       0.8682        0.9157  2.1721\n",
      "      8        \u001b[36m0.0019\u001b[0m       0.8693        0.9992  2.1906\n",
      "      9        0.0034       \u001b[32m0.8784\u001b[0m        0.8769  2.2255\n",
      "     10        \u001b[36m0.0011\u001b[0m       0.8750        1.0823  2.1778\n",
      "     11        0.0020       \u001b[32m0.8852\u001b[0m        1.1661  2.1521\n",
      "     12        0.0040       0.8852        0.9287  2.1975\n",
      "     13        0.0366       \u001b[32m0.8955\u001b[0m        0.7961  2.1587\n",
      "     14        0.0317       0.8682        \u001b[35m0.5860\u001b[0m  2.1605\n",
      "     15        0.0111       0.8648        0.8518  2.1420\n",
      "     16        \u001b[36m0.0011\u001b[0m       0.8795        0.7383  2.1288\n",
      "     17        \u001b[36m0.0002\u001b[0m       0.8830        0.7765  2.1418\n",
      "     18        \u001b[36m0.0001\u001b[0m       0.8807        0.8365  2.1412\n",
      "     19        \u001b[36m0.0001\u001b[0m       0.8795        0.8674  2.1505\n",
      "     20        \u001b[36m0.0001\u001b[0m       0.8795        0.8899  2.1609\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0061\u001b[0m       \u001b[32m0.8730\u001b[0m        \u001b[35m0.9755\u001b[0m  2.1664\n",
      "      2        0.0108       \u001b[32m0.8923\u001b[0m        \u001b[35m0.6427\u001b[0m  2.1734\n",
      "      3        0.0063       0.8651        1.0047  2.1847\n",
      "      4        \u001b[36m0.0045\u001b[0m       0.8776        1.1125  2.1818\n",
      "      5        0.0093       0.8639        1.0950  2.2026\n",
      "      6        \u001b[36m0.0021\u001b[0m       0.8787        0.7199  2.2269\n",
      "      7        \u001b[36m0.0009\u001b[0m       0.8719        0.9216  2.2181\n",
      "      8        \u001b[36m0.0002\u001b[0m       0.8776        0.9294  2.1764\n",
      "      9        \u001b[36m0.0001\u001b[0m       0.8741        0.9968  2.1732\n",
      "     10        \u001b[36m0.0000\u001b[0m       0.8741        1.0155  2.1831\n",
      "     11        \u001b[36m0.0000\u001b[0m       0.8741        1.0308  2.1901\n",
      "     12        \u001b[36m0.0000\u001b[0m       0.8741        1.0445  2.1894\n",
      "     13        \u001b[36m0.0000\u001b[0m       0.8753        1.0571  2.1974\n",
      "     14        \u001b[36m0.0000\u001b[0m       0.8753        1.0688  2.1548\n",
      "     15        \u001b[36m0.0000\u001b[0m       0.8741        1.0798  2.1578\n",
      "     16        \u001b[36m0.0000\u001b[0m       0.8730        1.0900  2.1745\n",
      "     17        \u001b[36m0.0000\u001b[0m       0.8730        1.0997  2.1563\n",
      "     18        \u001b[36m0.0000\u001b[0m       0.8730        1.1089  2.1462\n",
      "     19        \u001b[36m0.0000\u001b[0m       0.8730        1.1177  2.1491\n",
      "     20        \u001b[36m0.0000\u001b[0m       0.8730        1.1260  2.1960\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0079\u001b[0m       \u001b[32m0.8620\u001b[0m        \u001b[35m1.2055\u001b[0m  2.2470\n",
      "      2        \u001b[36m0.0063\u001b[0m       \u001b[32m0.8699\u001b[0m        \u001b[35m0.9542\u001b[0m  2.1672\n",
      "      3        0.0100       \u001b[32m0.8790\u001b[0m        \u001b[35m0.6654\u001b[0m  2.1752\n",
      "      4        \u001b[36m0.0038\u001b[0m       0.8744        0.7789  2.1725\n",
      "      5        \u001b[36m0.0005\u001b[0m       0.8778        0.7726  2.1619\n",
      "      6        \u001b[36m0.0001\u001b[0m       \u001b[32m0.8801\u001b[0m        0.8372  2.1770\n",
      "      7        \u001b[36m0.0000\u001b[0m       0.8801        0.8593  2.1772\n",
      "      8        \u001b[36m0.0000\u001b[0m       0.8801        0.8752  2.1602\n",
      "      9        \u001b[36m0.0000\u001b[0m       0.8801        0.8895  2.1673\n",
      "     10        \u001b[36m0.0000\u001b[0m       0.8801        0.9027  2.1798\n",
      "     11        \u001b[36m0.0000\u001b[0m       0.8801        0.9150  2.1588\n",
      "     12        \u001b[36m0.0000\u001b[0m       0.8790        0.9265  2.1579\n",
      "     13        \u001b[36m0.0000\u001b[0m       0.8778        0.9373  2.1943\n",
      "     14        \u001b[36m0.0000\u001b[0m       0.8778        0.9475  2.1584\n",
      "     15        \u001b[36m0.0000\u001b[0m       0.8778        0.9572  2.1918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16        \u001b[36m0.0000\u001b[0m       0.8778        0.9664  2.2158\n",
      "     17        \u001b[36m0.0000\u001b[0m       0.8778        0.9752  2.2503\n",
      "     18        \u001b[36m0.0000\u001b[0m       0.8778        0.9836  2.1610\n",
      "     19        \u001b[36m0.0000\u001b[0m       0.8778        0.9917  2.1517\n",
      "     20        \u001b[36m0.0000\u001b[0m       0.8778        0.9995  2.2506\n"
     ]
    }
   ],
   "source": [
    "co_clf = CoTrainingClassifier(cnn_1, RandomForestClassifier(), k=10, u=200)\n",
    "co_clf.fit(X1, X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "pkl_dir = \"pkl/\"\n",
    "with open(pkl_dir + \"new_model_co_training.pkl\", \"wb\") as f:\n",
    "    pickle.dump(co_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "def get_test_data(threshold):\n",
    "    test_dir = \"npy/val/\"\n",
    "    new_test_dir = test_dir + \"threshold_\" + str(threshold)\n",
    "    all_files = glob.glob(new_test_dir + \"/*\")\n",
    "    # export\n",
    "    all_npy = []\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    print(len(all_files))\n",
    "    for idx, file in enumerate(all_files):\n",
    "        if idx % 10000 == 0:\n",
    "            print(idx)\n",
    "        # get contextual features\n",
    "        features = (file.split('/')[3]).split('_')\n",
    "        filename = features[0]\n",
    "        features_dict = {'total_water_column': float(features[2]), 'depth': float(features[3]), 'relative_altitude': float(features[4]), 'latitude': float(features[5]), 'longitude': float(features[6]), 'time': features[7]}               \n",
    "        # get label: 0 - neg, 1 - pos, -1 - unlabeled\n",
    "        label = int(features[8].split('.')[0])       \n",
    "        if label == 4:\n",
    "            label = 1\n",
    "        elif label == 0:\n",
    "#             if filename in annotations_dict:\n",
    "#                 label = -1\n",
    "#             else:\n",
    "#                 label = 0\n",
    "              label = -1\n",
    "        else:\n",
    "            label = 0\n",
    "        # select, only labeled data\n",
    "        if label == 0 or label == 1: \n",
    "            # get npy\n",
    "            npy = np.load(file)\n",
    "            npy = np.transpose(npy, (2, 0, 1))\n",
    "            all_npy.append(npy)\n",
    "            all_features.append(features_dict)             \n",
    "            all_labels.append(label)\n",
    "    return np.array(all_npy), all_features, np.array(all_labels)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90844\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n"
     ]
    }
   ],
   "source": [
    "X1_test, X_feats_test, y_test = get_test_data(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to X2, (n_samples, n_features)\n",
    "feats_df = pd.DataFrame(X_feats_test)\n",
    "feats_df_sel = feats_df[sel_feats] # select features\n",
    "X2_test = feats_df_sel.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X1 to float\n",
    "X1_test = X1_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 4, 100, 100)\n",
      "(261, 4)\n",
      "(array([0, 1]), array([ 45, 216]))\n"
     ]
    }
   ],
   "source": [
    "print(X1_test.shape)\n",
    "print(X2_test.shape)\n",
    "print(np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9130434782608695, 'recall': 0.875, 'f1-score': 0.8936170212765957, 'support': 216}\n"
     ]
    }
   ],
   "source": [
    "c_y_predict = co_clf.predict(X1_test, X2_test)\n",
    "CO_report = classification_report(y_test, c_y_predict, output_dict=True)\n",
    "print(CO_report['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Using only RF model\n",
    "\n",
    "In this step, we'll use only RF model to do classification. See how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change -1 to 0\n",
    "y_change = []\n",
    "X2_change = []\n",
    "for idx, item in enumerate(y):\n",
    "    if item == -1:\n",
    "        y_change.append(0)\n",
    "    else:\n",
    "        y_change.append(item)\n",
    "    X2_change.append(X2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove -1\n",
    "y_remove = []\n",
    "X1_remove = []\n",
    "X2_remove = []\n",
    "for idx, item in enumerate(y):\n",
    "    if item != -1:\n",
    "        y_remove.append(item)\n",
    "        X1_remove.append(X1[idx])\n",
    "        X2_remove.append(X2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier() # LogisticRegression()\n",
    "rf_clf.fit(np.array(X2_remove), np.array(y_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.9624413145539906, 'recall': 0.9490740740740741, 'f1-score': 0.9557109557109558, 'support': 216}\n"
     ]
    }
   ],
   "source": [
    "rf_predict = rf_clf.predict(X2_test)\n",
    "RF_report = classification_report(y_test, rf_predict, output_dict=True)\n",
    "print(RF_report['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Using only CNN model\n",
    "\n",
    "In this step, we'll use only CNN model to do classification. See how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model_ft = models.resnet18(pretrained=False)\n",
    "# change input to 4 channels\n",
    "model_ft.conv1 = torch.nn.Conv2d(4, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False) # 4 channels\n",
    "# define device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "cnn_2 = NeuralNetClassifier(model_ft, criterion=nn.CrossEntropyLoss(), max_epochs=20, lr=0.001, optimizer=optim.Adam, device=device)\n",
    "# by default, 80/20 - train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0751\u001b[0m       \u001b[32m0.6323\u001b[0m        \u001b[35m1.1918\u001b[0m  2.1484\n",
      "      2        \u001b[36m0.2395\u001b[0m       \u001b[32m0.8202\u001b[0m        \u001b[35m0.3239\u001b[0m  2.1805\n",
      "      3        \u001b[36m0.1983\u001b[0m       \u001b[32m0.8213\u001b[0m        \u001b[35m0.3127\u001b[0m  2.1967\n",
      "      4        \u001b[36m0.1606\u001b[0m       \u001b[32m0.8499\u001b[0m        \u001b[35m0.2798\u001b[0m  2.2211\n",
      "      5        \u001b[36m0.1468\u001b[0m       0.8419        0.2991  2.2570\n",
      "      6        \u001b[36m0.1453\u001b[0m       0.8247        0.4394  2.5735\n",
      "      7        \u001b[36m0.1338\u001b[0m       \u001b[32m0.8648\u001b[0m        0.2934  2.1233\n",
      "      8        \u001b[36m0.1184\u001b[0m       0.8545        \u001b[35m0.2695\u001b[0m  2.1638\n",
      "      9        \u001b[36m0.1034\u001b[0m       \u001b[32m0.8843\u001b[0m        \u001b[35m0.2425\u001b[0m  2.1273\n",
      "     10        \u001b[36m0.0811\u001b[0m       0.8259        0.4173  2.9050\n",
      "     11        0.0903       0.8591        0.2829  2.6586\n",
      "     12        \u001b[36m0.0767\u001b[0m       0.8328        0.4039  2.4278\n",
      "     13        0.0769       0.8729        0.3181  2.2302\n",
      "     14        0.0879       0.8522        0.4480  2.1236\n",
      "     15        \u001b[36m0.0736\u001b[0m       0.8660        0.4069  2.1204\n",
      "     16        \u001b[36m0.0668\u001b[0m       0.8557        0.5797  2.1251\n",
      "     17        0.0805       0.8477        0.6442  2.1205\n",
      "     18        0.0776       0.8557        0.6843  2.1282\n",
      "     19        \u001b[36m0.0618\u001b[0m       0.8786        0.3219  2.1245\n",
      "     20        \u001b[36m0.0378\u001b[0m       \u001b[32m0.8877\u001b[0m        0.4503  2.1177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ResNet(\n",
       "    (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_2.fit(np.array(X1_remove), np.array(y_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open(pkl_dir + \"new_model_cnn.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cnn_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8761904761904762, 'recall': 0.8518518518518519, 'f1-score': 0.863849765258216, 'support': 216}\n"
     ]
    }
   ],
   "source": [
    "# test!\n",
    "cnn_predict = cnn_2.predict(X1_test)\n",
    "CNN_report = classification_report(y_test, cnn_predict, output_dict=True)\n",
    "print(CNN_report['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
