{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 - ROI features\n",
    "\n",
    "In this notebook, we'll separate 2019 data (only annotated) into train & test echograms, perform ROI detection, assign ROI label, ROI features, ROI images. Save them into train & test set, for further steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from src.read_echogram import EchogramReader\n",
    "from src.detect_ROI import ROIDetector\n",
    "from src.ROI_features import FeatureExtractor\n",
    "from src.transform_annotations import AnnotationTransformer\n",
    "from src.match_annotations import OverlapAnnotation\n",
    "from src.crop_ROI import ROICropper\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load annotations & separate train & test\n",
    "\n",
    "In this step, we'll load annotation filenames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original annotations (mask)\n",
    "annotations_dir = \"../csv/\"\n",
    "annotations = pd.read_csv(annotations_dir + \"annotation_df_masks.csv\")\n",
    "# drop nan\n",
    "annotations = annotations.dropna(how='any')\n",
    "# add label map\n",
    "label_map = {'Unclassified regions': 1, 'krill_schools': 2, 'fish_school': 3, 'AH_School': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select echograms with AH schools\n",
    "filename_li = annotations['file_dir'].unique()\n",
    "filename_li.sort() # get filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filename_li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, separate train & test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotations\n",
    "pkl_dir = \"pkl/\"\n",
    "with open(pkl_dir + 'annotations_dict_new.pickle', 'rb') as handle:\n",
    "    annotations_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "echogram_li = annotations_dict.keys() # key - filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "test_examples = ['D20190927-T072325', 'D20191016-T184753', 'D20191016-T213424', 'D20191018-T081659', 'D20191018-T110329', 'D20191020-T145420', 'D20191024-T103607', 'D20191024-T172924', 'D20191102-T144417', 'D20191102-T160647'] # 10\n",
    "# test_examples = ['D20191102-T14441', 'D20191024-T172924', 'D20191023-T130820', 'D20190927-T072325']\n",
    "other_test_examples = random.sample(list(set(echogram_li) - set(test_examples)), k=40)\n",
    "# combine into test\n",
    "test_echogram_li = test_examples + other_test_examples\n",
    "# test_echogram_li = random.sample(echogram_li, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_echogram_li = [i for i in echogram_li if i not in test_echogram_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(811, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_echogram_li), len(test_echogram_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to keep train/test consistent\n",
    "pkl_dir = \"pkl/\"\n",
    "with open(pkl_dir + 'train_echogram_li.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_echogram_li, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(pkl_dir + 'test_echogram_li.pickle', 'wb') as handle:\n",
    "    pickle.dump(test_echogram_li, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Get ROI features, label, and npy (saved)\n",
    "\n",
    "In this step, we'll run ROI detection on each file, get features, match with annotations (to get labels), crop images (saved as numpy array). Add ROI id if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add raw and bottom file dir\n",
    "raw_dir = \"../data/HB1906_EK60/rawfiles/\"\n",
    "bot_dir = \"../data/HB1906_EK60/botfiles/\"\n",
    "freq_li = [18, 38, 120, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_paths = sorted(glob.glob(raw_dir + '*.raw'))\n",
    "bot_paths = sorted(glob.glob(bot_dir + '*.bot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = \"figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parameters\n",
    "threshold = -66\n",
    "kernel_size = 3\n",
    "overlap_ratio = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY parallel processing! Est. 4 hours -> Much faster after upgrading ipython, est. 2 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI(a):\n",
    "    i, j = a\n",
    "    if i not in filename_li:\n",
    "        return \n",
    "    echogram = EchogramReader(i, j, freq_li)\n",
    "    filename, Sv_npy, surface_idx, bottom_idx, time, depth, positions = echogram()   \n",
    "    annotations_idx, labels = annotations_dict[filename] # get annotation xy indices directly\n",
    "    # detect ROIs\n",
    "    roi = ROIDetector(filename, Sv_npy, surface_idx, bottom_idx, fig_dir, threshold, kernel_size)\n",
    "    img_shape, contours = roi()\n",
    "    features = FeatureExtractor(filename, contours, Sv_npy, bottom_idx, time, depth, positions) \n",
    "    # ROI features\n",
    "    contours_sel, contours_features = features() # return a list\n",
    "    try:\n",
    "        overlap = OverlapAnnotation(filename, img_shape, annotations_idx, labels, contours_sel, fig_dir) \n",
    "        contours_labels = overlap.assign_label(overlap_ratio) # get label\n",
    "        for idx, contour in enumerate(contours_features):\n",
    "            contour['label'] = contours_labels[idx] # add\n",
    "        # ROI npy, select dir\n",
    "        if filename in train_echogram_li:\n",
    "            npy_dir = \"npy_new/train/\"\n",
    "        if filename in test_echogram_li:\n",
    "            npy_dir = \"npy_new/test/\"\n",
    "        crop = ROICropper(filename, contours_sel, contours_labels, Sv_npy, npy_dir)\n",
    "        crop()\n",
    "        return contours_features\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "pool = Pool(os.cpu_count()) # \n",
    "res_li = pool.map(ROI, zip(raw_paths, bot_paths)) # a list of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for sublist in res_li:\n",
    "    if sublist == None:\n",
    "        continue\n",
    "    for item in sublist:\n",
    "        res.append(item)\n",
    "df_roi_features = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = \"pkl/\"\n",
    "df_roi_features.to_pickle(pkl_dir + 'df_roi_features_new.pkl') # *_new with kernel_size == 1, for abundance estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
