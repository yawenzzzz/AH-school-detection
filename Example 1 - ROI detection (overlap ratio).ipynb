{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - ROI detection\n",
    "\n",
    "In this notebook, we'll perform ROI detection on echograms, and evaluate its performance using annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from src.read_echogram import EchogramReader\n",
    "from src.detect_ROI import ROIDetector\n",
    "from src.ROI_features import FeatureExtractor\n",
    "from src.transform_annotations import AnnotationTransformer\n",
    "from src.match_annotations import OverlapAnnotation\n",
    "from src.crop_ROI import ROICropper\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load annotations\n",
    "\n",
    "In this step, we'll load original and transformed annotations, i.e., filename: [annotations, labels], saved as pkl file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original annotations (mask)\n",
    "annotations_dir = \"../csv/\"\n",
    "annotations = pd.read_csv(annotations_dir + \"annotation_df_masks.csv\")\n",
    "# drop nan\n",
    "annotations = annotations.dropna(how='any')\n",
    "# add label map\n",
    "label_map = {'Unclassified regions': 1, 'krill_schools': 2, 'fish_school': 3, 'AH_School': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select echograms with AH schools\n",
    "annotations_sel = annotations[annotations['label'] == 'AH_School']\n",
    "filename_li = annotations_sel['file_dir'].unique()\n",
    "filename_li.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filename_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transformed annotations (query)\n",
    "pkl_dir = \"pkl/\"\n",
    "with open(pkl_dir + 'annotations_dict_new.pickle', 'rb') as handle:\n",
    "    annotations_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Parameter study (overlap ratio)\n",
    "\n",
    "In this step, we will test out how threshold and kernel_size impact recall, precision, and IoU in ROI detection. There are 1710 echograms in 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add raw and bottom file dir\n",
    "raw_dir = \"../data/HB1906_EK60/rawfiles/\"\n",
    "bot_dir = \"../data/HB1906_EK60/botfiles/\"\n",
    "freq_li = [18, 38, 120, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_paths = sorted(glob.glob(raw_dir + '*.raw'))\n",
    "bot_paths = sorted(glob.glob(bot_dir + '*.bot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = \"figures/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's test out overlap ratio & recall/precision/F1. All with -66dB threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -66\n",
    "kernel_size = 3\n",
    "overlap_ratio_li = [0.0, 0.2, 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_overlap(a):\n",
    "    i, j = a\n",
    "    if i not in filename_li:\n",
    "        return\n",
    "    echogram = EchogramReader(i, j, freq_li)\n",
    "    filename, Sv_npy, surface_idx, bottom_idx, time, depth, positions = echogram()   \n",
    "    annotations_idx, labels = annotations_dict[filename] # get annotation xy indices directly\n",
    "    # detect ROIs\n",
    "    roi = ROIDetector(filename, Sv_npy, surface_idx, bottom_idx, fig_dir, threshold, kernel_size)\n",
    "    img_shape, contours = roi()\n",
    "    features = FeatureExtractor(filename, contours, Sv_npy, bottom_idx, time, depth, positions)                    \n",
    "    contours_sel, contours_features = features() \n",
    "    temp_res = []\n",
    "    for overlap_ratio in overlap_ratio_li:\n",
    "        try:\n",
    "            # match ROIs with annotations, bug: with only 1 annotations - D20191111-T080459\n",
    "            overlap = OverlapAnnotation(filename, img_shape, annotations_idx, labels, contours_sel, fig_dir) \n",
    "            # object-level metrics\n",
    "            counts = overlap.object_overlap_count(overlap_ratio) # set threshold   \n",
    "            res_dict = {'filename': filename, 'threshold': threshold, 'kernel_size': kernel_size, 'overlap_ratio': overlap_ratio, 'annotations_valid': counts[0], 'annotations_all': counts[1], 'roi_valid': counts[2], 'roi_all': counts[3]}\n",
    "            temp_res.append(res_dict)\n",
    "        except:\n",
    "            continue\n",
    "    return temp_res     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using multiprocessing, about 1 hour. Exactly 254 files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "pool = Pool(os.cpu_count())\n",
    "res_li = pool.map(test_overlap, zip(raw_paths, bot_paths)) # a list of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for sublist in res_li:\n",
    "    if sublist == None:\n",
    "        continue\n",
    "    for item in sublist:\n",
    "        res.append(item)\n",
    "df_overlap_ratio = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = \"pkl/\"\n",
    "df_overlap_ratio.to_pickle(pkl_dir + 'df_overlap_ratio_or.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get recall/precision/F1 at different overlap ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = \"pkl/\"\n",
    "df_overlap_ratio = pd.read_pickle(pkl_dir + 'df_overlap_ratio_or.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap ratio: 0.0, recall: 0.9529691211401425, precision: 0.19820891345413838, F1: 0.16408146123384276\n",
      "overlap ratio: 0.2, recall: 0.9439429928741092, precision: 0.1924018750437277, F1: 0.15982507325980058\n",
      "overlap ratio: 0.4, recall: 0.9135391923990499, precision: 0.17770936822220668, F1: 0.14876947249766456\n"
     ]
    }
   ],
   "source": [
    "for overlap_ratio in overlap_ratio_li:\n",
    "    df = df_overlap_ratio[df_overlap_ratio['overlap_ratio']==overlap_ratio]\n",
    "    recall = df['annotations_valid'].sum() / df['annotations_all'].sum()\n",
    "    precision = df['roi_valid'].sum() / df['roi_all'].sum()\n",
    "    F1 = 1.0/(1.0/recall + 1.0/precision)\n",
    "    print(f'overlap ratio: {overlap_ratio}, recall: {recall}, precision: {precision}, F1: {F1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Check depth issue\n",
    "\n",
    "The original echogram's depth starts at 7.5m, while annotations start at 6m, add 1.5m as offset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.           6.19132538   6.38265076 ... 505.35924545 505.55057083\n",
      " 505.74189621]\n"
     ]
    }
   ],
   "source": [
    "print(depth) # depth varies, 6m or 7.5m, annotations, buffer 6m, add offset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
