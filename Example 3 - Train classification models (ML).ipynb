{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 - Train classification models (ML)\n",
    "\n",
    "In this notebook, we'll train classification models (CNN, RF, PU-learning, Co-training), see how they performs? Also, saved those models for prediction on test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from src.read_echogram import EchogramReader\n",
    "from src.detect_ROI import ROIDetector\n",
    "from src.ROI_features import FeatureExtractor\n",
    "from src.transform_annotations import AnnotationTransformer\n",
    "from src.match_annotations import OverlapAnnotation\n",
    "from src.crop_ROI import ROICropper\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Separate train & test data\n",
    "\n",
    "In this step, we'll separate 2019 data (861 annotated ones) into train & test files. In total, 50 files for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train\n",
    "pkl_dir = \"pkl/\"\n",
    "with open(pkl_dir + 'train_echogram_li.pickle', 'rb') as handle:\n",
    "    train_echogram_li = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test\n",
    "pkl_dir = \"pkl/\"\n",
    "with open(pkl_dir + 'test_echogram_li.pickle', 'rb') as handle:\n",
    "    test_echogram_li = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add label map\n",
    "label_map = {'Unclassified regions': 1, 'krill_schools': 2, 'fish_school': 3, 'AH_School': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Train classification models (RF, PU, Co-training)\n",
    "\n",
    "In this step, we'll train classification models to differentiate AH and other categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.classifiers import CoTrainingClassifier\n",
    "from pulearn import ElkanotoPuClassifier, BaggingPuClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label map\n",
    "label_map = {'None': 0, 'Unclassified regions': 1, 'krill_schools': 2, 'fish_school': 3, 'AH_School': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ROI features\n",
    "pkl_dir = \"pkl/\"\n",
    "df_roi_features = pd.read_pickle(pkl_dir + 'df_roi_features.pkl') # *_new, kernel_size = 1, for abundance estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.100876733660698"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roi_features['thickness'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.027441581837877"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roi_features['length'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26438\n"
     ]
    }
   ],
   "source": [
    "print(df_roi_features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define feature set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_features = ['Sv_18kHz_min', 'Sv_18kHz_p5', 'Sv_18kHz_p25', 'Sv_18kHz_p50', 'Sv_18kHz_p75', 'Sv_18kHz_p95', 'Sv_18kHz_max', 'Sv_18kHz_std', 'Sv_38kHz_min', 'Sv_38kHz_p5', 'Sv_38kHz_p25', 'Sv_38kHz_p50', 'Sv_38kHz_p75', 'Sv_38kHz_p95', 'Sv_38kHz_max', 'Sv_38kHz_std', 'Sv_120kHz_min', 'Sv_120kHz_p5', 'Sv_120kHz_p25', 'Sv_120kHz_p50', 'Sv_120kHz_p75', 'Sv_120kHz_p95', 'Sv_120kHz_max', 'Sv_120kHz_std', 'Sv_200kHz_min', 'Sv_200kHz_p5', 'Sv_200kHz_p25', 'Sv_200kHz_p50', 'Sv_200kHz_p75', 'Sv_200kHz_p95', 'Sv_200kHz_max', 'Sv_200kHz_std', 'Sv_ref_18kHz', 'Sv_ref_120kHz', 'Sv_ref_200kHz']\n",
    "geometric_features = ['length', 'thickness', 'area', 'perimeter', 'rectangularity', 'compact', 'circularity', 'elongation']\n",
    "geographic_features_vertical = ['total_water_column', 'depth', 'relative_altitude']\n",
    "geographic_features_horizontal = ['latitude', 'longitude']\n",
    "sel_features = acoustic_features # + geometric_features + geographic_features_vertical + geographic_features_horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_roi_features[sel_features] = min_max_scaler.fit_transform(df_roi_features[sel_features])\n",
    "df_roi_features = df_roi_features.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = df_roi_features[df_roi_features['filename'].isin(train_echogram_li)]\n",
    "# separate into pos, neg, unlabeled set\n",
    "positive_set = train_features[train_features['label']==4]\n",
    "negative_set = train_features[train_features['label'].isin([1, 2, 3])]\n",
    "unlabeled_set = train_features[train_features['label']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there, do we need to keep the original ratio of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23391 2087 1007 20297\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape[0], positive_set.shape[0], negative_set.shape[0], unlabeled_set.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10154/2225180614.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set['label'] = test_set['label'].apply(lambda x: 1 if x==4 else 0) # Use 1 and 0\n"
     ]
    }
   ],
   "source": [
    "test_features = df_roi_features[df_roi_features['filename'].isin(test_echogram_li)]\n",
    "# select only labeled\n",
    "test_set = test_features[test_features['label']!=0]\n",
    "test_set['label'] = test_set['label'].apply(lambda x: 1 if x==4 else 0) # Use 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3047\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_set[sel_features].to_numpy()\n",
    "y_test = test_set['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([105, 453]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use different number of positive samples\n",
    "\n",
    "Try using different number of positive samples for model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087\n"
     ]
    }
   ],
   "source": [
    "max_k = positive_set.shape[0]\n",
    "print(max_k)\n",
    "# k_li = list(range(500, max_k, 100))\n",
    "k_li = [max_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = \"pkl/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF model (only positive, only acoustic features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087 {'precision': 0.9470899470899471, 'recall': 0.7902869757174393, 'f1-score': 0.861612515042118, 'support': 453}\n"
     ]
    }
   ],
   "source": [
    "res_RF = []\n",
    "for idx, k in enumerate(k_li):\n",
    "    positive_set_sel = positive_set.sample(k, random_state=0)\n",
    "    unlabeled_set_sel = unlabeled_set.sample(1 * k - negative_set.shape[0])\n",
    "    train_set = pd.concat([positive_set_sel, negative_set, unlabeled_set_sel], ignore_index=True)\n",
    "    train_set['label'] = train_set['label'].apply(lambda x: 1 if x==4 else 0)\n",
    "    X_train = train_set[sel_features].to_numpy()\n",
    "    y = np.array(train_set['label'].tolist())\n",
    "    base_rf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "    base_rf.fit(X_train, y)\n",
    "    c_y_predict = base_rf.predict(X_test)\n",
    "    RF_report = classification_report(y_test, c_y_predict, output_dict=True)\n",
    "    print(k, RF_report['1'])\n",
    "    # add\n",
    "    res_RF.append({'size': k, 'RF_recall': RF_report['1']['recall'], 'RF_precision': RF_report['1']['precision'], 'RF_f1': RF_report['1']['f1-score']})\n",
    "    # save model\n",
    "    if idx == (len(k_li) - 1):       \n",
    "        with open(pkl_dir + \"model_RF_only_acoustic.pkl\", 'wb') as f:\n",
    "            pickle.dump(base_rf, f)\n",
    "# save\n",
    "res_RF_pd = pd.DataFrame(res_RF)\n",
    "res_RF_pd.to_pickle(pkl_dir + 'results_RF_only_acoustic.pkl')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF model (only positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087 {'precision': 0.9951100244498777, 'recall': 0.8984547461368654, 'f1-score': 0.9443155452436195, 'support': 453}\n"
     ]
    }
   ],
   "source": [
    "res_RF = []\n",
    "for idx, k in enumerate(k_li):\n",
    "    positive_set_sel = positive_set.sample(k, random_state=0)\n",
    "    unlabeled_set_sel = unlabeled_set.sample(k - negative_set.shape[0]) # minus negative set\n",
    "    train_set = pd.concat([positive_set_sel, negative_set, unlabeled_set_sel], ignore_index=True)\n",
    "    train_set['label'] = train_set['label'].apply(lambda x: 1 if x==4 else 0)\n",
    "    X_train = train_set[sel_features].to_numpy()\n",
    "    y = np.array(train_set['label'].tolist())\n",
    "    base_rf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "    base_rf.fit(X_train, y)\n",
    "    c_y_predict = base_rf.predict(X_test)\n",
    "    RF_report = classification_report(y_test, c_y_predict, output_dict=True)\n",
    "    print(k, RF_report['1'])\n",
    "    # add\n",
    "    res_RF.append({'size': k, 'RF_recall': RF_report['1']['recall'], 'RF_precision': RF_report['1']['precision'], 'RF_f1': RF_report['1']['f1-score']})\n",
    "    # save model\n",
    "    if idx == (len(k_li) - 1):       \n",
    "        with open(pkl_dir + \"model_RF.pkl\", 'wb') as f:\n",
    "            pickle.dump(base_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "res_RF_pd = pd.DataFrame(res_RF)\n",
    "res_RF_pd.to_pickle(pkl_dir + 'results_RF.pkl')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PU learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087 {'precision': 0.9954022988505747, 'recall': 0.9558498896247241, 'f1-score': 0.9752252252252254, 'support': 453}\n"
     ]
    }
   ],
   "source": [
    "res_PU = []\n",
    "for idx, k in enumerate(k_li):\n",
    "    positive_set_sel = positive_set.sample(k, random_state=0)\n",
    "    unlabeled_set_sel = unlabeled_set.sample(k - negative_set.shape[0])\n",
    "    train_set = pd.concat([positive_set_sel, negative_set, unlabeled_set_sel], ignore_index=True)\n",
    "    train_set['label'] = train_set['label'].apply(lambda x: 1 if x==4 else -1)\n",
    "    X_train = train_set[sel_features].to_numpy()\n",
    "    y = np.array(train_set['label'].tolist())\n",
    "    # change 0 to -1\n",
    "    y_test_new = [-1 if x==0 else x for x in y_test]\n",
    "    c = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "    pu_estimator = ElkanotoPuClassifier(estimator=c, hold_out_ratio=0.2)\n",
    "    pu_estimator.fit(X_train, y)\n",
    "    c_y_predict = pu_estimator.predict(X_test)\n",
    "    PU_report = classification_report(y_test_new, c_y_predict, output_dict=True)\n",
    "    print(k, PU_report['1'])\n",
    "    # add\n",
    "    res_PU.append({'size': k, 'PU_recall': PU_report['1']['recall'], 'PU_precision': PU_report['1']['precision'], 'PU_f1': PU_report['1']['f1-score']})\n",
    "    # save model\n",
    "    if idx == (len(k_li) - 1):       \n",
    "        with open(pkl_dir + \"model_PU.pkl\", 'wb') as f:\n",
    "            pickle.dump(pu_estimator, f)\n",
    "# save res\n",
    "res_PU_pd = pd.DataFrame(res_PU)\n",
    "res_PU_pd.to_pickle(pkl_dir + 'results_PU.pkl')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out how the labeled:unlabeled ratio impact the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'precision': 0.9953810623556582, 'recall': 0.9514348785871964, 'f1-score': 0.9729119638826185, 'support': 453}\n",
      "2 {'precision': 0.9951456310679612, 'recall': 0.9050772626931567, 'f1-score': 0.9479768786127167, 'support': 453}\n",
      "3 {'precision': 0.9873737373737373, 'recall': 0.8631346578366446, 'f1-score': 0.9210836277974087, 'support': 453}\n",
      "4 {'precision': 0.9894736842105263, 'recall': 0.8300220750551877, 'f1-score': 0.9027611044417767, 'support': 453}\n",
      "5 {'precision': 0.9943502824858758, 'recall': 0.7770419426048565, 'f1-score': 0.8723667905824039, 'support': 453}\n",
      "6 {'precision': 0.9915966386554622, 'recall': 0.7814569536423841, 'f1-score': 0.874074074074074, 'support': 453}\n",
      "7 {'precision': 0.9940119760479041, 'recall': 0.7328918322295805, 'f1-score': 0.843710292249047, 'support': 453}\n",
      "8 {'precision': 0.9940298507462687, 'recall': 0.7350993377483444, 'f1-score': 0.8451776649746192, 'support': 453}\n",
      "9 {'precision': 0.9882697947214076, 'recall': 0.7439293598233996, 'f1-score': 0.8488664987405541, 'support': 453}\n",
      "10 {'precision': 0.9851632047477745, 'recall': 0.7328918322295805, 'f1-score': 0.8405063291139241, 'support': 453}\n"
     ]
    }
   ],
   "source": [
    "res_times = []\n",
    "times = list(range(1, 11, 1)) # can be max 10\n",
    "for item in times:\n",
    "    positive_set_sel = positive_set.sample(max_k, random_state=0)\n",
    "    unlabeled_set_sel = unlabeled_set.sample(item * max_k - negative_set.shape[0], replace=True) # \n",
    "    train_set = pd.concat([positive_set_sel, negative_set, unlabeled_set_sel], ignore_index=True)\n",
    "    train_set['label'] = train_set['label'].apply(lambda x: 1 if x==4 else -1)\n",
    "    X_train = train_set[sel_features].to_numpy()\n",
    "    y = np.array(train_set['label'].tolist())\n",
    "    # change 0 to -1\n",
    "    y_test_new = [-1 if x==0 else x for x in y_test]\n",
    "    c = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "    pu_estimator = ElkanotoPuClassifier(estimator=c, hold_out_ratio=0.2)\n",
    "    pu_estimator.fit(X_train, y)\n",
    "    c_y_predict = pu_estimator.predict(X_test)\n",
    "    PU_report = classification_report(y_test_new, c_y_predict, output_dict=True)\n",
    "    print(item, PU_report['1'])\n",
    "    res_times.append({'time': item, 'PU_recall': PU_report['1']['recall'], 'PU_precision': PU_report['1']['precision'], 'PU_f1': PU_report['1']['f1-score']})\n",
    "# save res\n",
    "res_times_pd = pd.DataFrame(res_times)\n",
    "res_times_pd.to_pickle(pkl_dir + 'results_PU_times.pkl')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087 {'precision': 0.9933774834437086, 'recall': 0.9933774834437086, 'f1-score': 0.9933774834437086, 'support': 453}\n"
     ]
    }
   ],
   "source": [
    "res_co = []\n",
    "for idx, k in enumerate(k_li):\n",
    "    positive_set_sel = positive_set.sample(k, random_state=0)\n",
    "    unlabeled_set_sel = unlabeled_set.sample(k - negative_set.shape[0])\n",
    "    train_set = pd.concat([positive_set_sel, negative_set, unlabeled_set_sel], ignore_index=True)\n",
    "    # get -1: unlabeled, 0: negative, 1: positive\n",
    "    new_label_map = {0: -1, 1: 0, 2: 0, 3: 0, 4: 1}\n",
    "    train_set['label'] = train_set['label'].apply(lambda x: new_label_map[x]) # reset\n",
    "    X1 = train_set[acoustic_features + geometric_features].to_numpy()\n",
    "    X2 = train_set[geographic_features_horizontal + geographic_features_vertical].to_numpy()\n",
    "    y = np.array(train_set['label'].tolist())\n",
    "    rf_co_clf = CoTrainingClassifier(RandomForestClassifier(n_estimators=100))\n",
    "    rf_co_clf.fit(X1, X2, y)\n",
    "    # add test\n",
    "    X1_test = test_set[acoustic_features + geometric_features].to_numpy()\n",
    "    X2_test = test_set[geographic_features_horizontal + geographic_features_vertical].to_numpy()\n",
    "    c_y_predict = rf_co_clf.predict(X1_test, X2_test)\n",
    "    CO_report = classification_report(y_test, c_y_predict, output_dict=True)\n",
    "    print(k, CO_report['1'])\n",
    "    res_co.append({'size': k, 'CO_recall': CO_report['1']['recall'], 'CO_precision': CO_report['1']['precision'], 'CO_f1': CO_report['1']['f1-score']})\n",
    "    # save model\n",
    "    if idx == (len(k_li) - 1):       \n",
    "        with open(pkl_dir + \"model_CO.pkl\", 'wb') as f:\n",
    "            pickle.dump(rf_co_clf, f)\n",
    "# save res\n",
    "res_co_pd = pd.DataFrame(res_co)\n",
    "res_co_pd.to_pickle(pkl_dir + 'results_co.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
